from Lexer import TokenType


class Parser:
    def __init__(self, lexer):
        self.lexer = lexer
        self.current_token = self.lexer.get_next_token()

    def consume(self, expected_token_type):
        if self.current_token.type == expected_token_type:
            self.current_token = self.lexer.get_next_token()
        else:
            raise SyntaxError(f"Syntax error: exprected token type {expected_token_type}, "
                              f"but found token type {self.current_token.type}")


    def parser(self):
        result = self.concat()
        if self.current_token.type != TokenType.EOF:
            raise SyntaxError("fsfsfe")
        return result


    def concat(self):
        result = self.reverse()
        while self.current_token.type == TokenType.CONCAT:
            self.consume(TokenType.CONCAT)
            result += self.reverse()
        return result

    def reverse(self):
        result = self.power()
        if self.current_token.type == TokenType.INVERT:
            self.consume(TokenType.INVERT)
            result = result[::-1]
        return result


    def power(self):
        result = self.last()
        if self.current_token.type == TokenType.POWER:
            self.consume(TokenType.POWER)
            value = self.power()
            if not value.isdigit():
                raise ValueError("fwkgwoijgeijseg")
            result *= int(value)
        return result

    def last(self):
        if self.current_token.type == TokenType.STRING:
            value = self.current_token.attribute
            self.consume(TokenType.STRING)
            return value
        elif self.current_token.type == TokenType.LPAREN:
            self.consume(TokenType.LPAREN)
            result = self.concat()
            self.consume(TokenType.RPAREN)
            return result
        else:
            raise SyntaxError('skfjjgkrvhsiiger')
